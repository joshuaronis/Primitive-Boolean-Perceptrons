{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'm going to make all the primitive boolean functions into perceptrons. I will gve them each a 2D dataset, and have each of them learn a different primitive boolean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arbitraryPerceptron():\n",
    "    w = None    \n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.w = np.array([])\n",
    "        print(self.w)\n",
    "   \n",
    "    def selfTrain(self, r, data, labels):\n",
    "        self.w = np.random.randn(*data[0].shape)        \n",
    "        weightsBeforeTraining = np.random.randn(*self.w.shape)\n",
    "        \n",
    "        timesTraining = 0\n",
    "        \n",
    "        while list(weightsBeforeTraining)!=list(self.w):\n",
    "            i = 0\n",
    "\n",
    "            timesTraining = timesTraining+1\n",
    "            print(\"Training \" + str(timesTraining) + \"th time\")\n",
    "\n",
    "            weightsBeforeTraining = np.copy(self.w)\n",
    "\n",
    "            print(\"Weights before training: \" + str(list(weightsBeforeTraining)))\n",
    "            \n",
    "            for x in data:\n",
    "                o = np.sign(np.dot(self.w, x))\n",
    "                t = labels[i]\n",
    "\n",
    "                if o != labels[i]:\n",
    "                    for counter in range(len(self.w)):\n",
    "                        self.w[counter] = self.w[counter] + r*(t-o)*x[counter]   \n",
    "                i = i + 1\n",
    "            \n",
    "            print(\"Weights after training: \" + str(list(self.w)))\n",
    "            print(\"-------------\")\n",
    "\n",
    "        \n",
    "        print(\"-------------\")\n",
    "        print(\"-------------\")\n",
    "        print(\"Weights weren't changed by training. Every datapoint in trainingset was classified correctly. Training is done\")\n",
    "    \n",
    "    def predict(self, datapoint):\n",
    "        return np.sign(np.dot(self.w,datapoint))\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 1, 1], [1, -1, 1], [1, 1, -1], [1, -1, -1]]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function we will learn is the AND function. As you can see, the data is binary. There are three entries into each datapoint, but the first entry is just to scale the bias. \n",
    "\n",
    "Each label represents what we want our algorithm to learn for its corresponding datapoint, that is, the datapoint in data that has the same index as it does. \n",
    "\n",
    "Since we want our perceptron to learn the AND function, (1 stands for true, -1 stands for false), only the datapoints with both coordinates as 1, should have an output of 1 (true, true -> true), while the rest should have outputs of false.\n",
    "\n",
    "So, the label corresponding with [1, 1, 1] is 1, but with all the others (eg. [1, -1, -1]) its -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "andLabels = [1, -1, -1, -1]\n",
    "andLabels = np.array(andLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "AND = arbitraryPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1th time\n",
      "Weights before training: [-1.3685915078328552, 2.4269348139764944, 1.491239365977455]\n",
      "Weights after training: [-1.3685915078328552, 2.4269348139764944, 1.491239365977455]\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "Weights weren't changed by training. Every datapoint in trainingset was classified correctly. Training is done\n"
     ]
    }
   ],
   "source": [
    "AND.selfTrain(.1, data, andLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.36859151,  2.42693481,  1.49123937])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll learn the OR function. The data will remain the same, but the labels will change. Now, binary datapoints with True, False or False, True will also be labeled as True. Only False, False will be labeled as False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "orLabels = [1, 1, 1, -1] * 5\n",
    "orLabels = np.array(orLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "OR = arbitraryPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1th time\n",
      "Weights before training: [0.8601916966810278, 0.14560216006289647, 0.6389521233845212]\n",
      "Weights after training: [0.6601916966810277, 0.34560216006289646, 0.8389521233845212]\n",
      "-------------\n",
      "Training 2th time\n",
      "Weights before training: [0.6601916966810277, 0.34560216006289646, 0.8389521233845212]\n",
      "Weights after training: [0.6601916966810277, 0.34560216006289646, 0.8389521233845212]\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "Weights weren't changed by training. Every datapoint in trainingset was classified correctly. Training is done\n"
     ]
    }
   ],
   "source": [
    "OR.selfTrain(.1, data, orLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6601917 , 0.34560216, 0.83895212])"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NAND function is just the opposite of the AND function; that is, we negate all the labels. Notive that the weights end up being the complete oppositte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "nandLabels = [-1, 1, 1, 1] * 5\n",
    "nandLabels = np.array(nandLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "NAND = arbitraryPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1th time\n",
      "Weights before training: [1.376117939625867, 0.8945217177015813, 1.360713966034111]\n",
      "Weights after training: [1.376117939625867, 0.4945217177015812, 0.9607139660341111]\n",
      "-------------\n",
      "Training 2th time\n",
      "Weights before training: [1.376117939625867, 0.4945217177015812, 0.9607139660341111]\n",
      "Weights after training: [1.176117939625867, 0.2945217177015812, 0.7607139660341111]\n",
      "-------------\n",
      "Training 3th time\n",
      "Weights before training: [1.176117939625867, 0.2945217177015812, 0.7607139660341111]\n",
      "Weights after training: [0.976117939625867, 0.09452171770158119, 0.5607139660341112]\n",
      "-------------\n",
      "Training 4th time\n",
      "Weights before training: [0.976117939625867, 0.09452171770158119, 0.5607139660341112]\n",
      "Weights after training: [0.7761179396258671, -0.10547828229841882, 0.36071396603411116]\n",
      "-------------\n",
      "Training 5th time\n",
      "Weights before training: [0.7761179396258671, -0.10547828229841882, 0.36071396603411116]\n",
      "Weights after training: [0.5761179396258671, -0.30547828229841884, 0.16071396603411114]\n",
      "-------------\n",
      "Training 6th time\n",
      "Weights before training: [0.5761179396258671, -0.30547828229841884, 0.16071396603411114]\n",
      "Weights after training: [0.5761179396258671, -0.30547828229841884, -0.23928603396588888]\n",
      "-------------\n",
      "Training 7th time\n",
      "Weights before training: [0.5761179396258671, -0.30547828229841884, -0.23928603396588888]\n",
      "Weights after training: [0.3761179396258671, -0.5054782822984188, -0.4392860339658889]\n",
      "-------------\n",
      "Training 8th time\n",
      "Weights before training: [0.3761179396258671, -0.5054782822984188, -0.4392860339658889]\n",
      "Weights after training: [0.3761179396258671, -0.5054782822984188, -0.4392860339658889]\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "Weights weren't changed by training. Every datapoint in trainingset was classified correctly. Training is done\n"
     ]
    }
   ],
   "source": [
    "NAND.selfTrain(.1, data, nandLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37611794, -0.50547828, -0.43928603])"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for NOR, the labels should be the negative of OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "norLabels = [-1, -1, -1, 1] * 5\n",
    "norLabels = np.array(norLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "NOR = arbitraryPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1th time\n",
      "Weights before training: [-0.025236819915359174, -0.6086053836458482, 0.34813039726040673]\n",
      "Weights after training: [-0.22523681991535918, -0.40860538364584814, 0.14813039726040672]\n",
      "-------------\n",
      "Training 2th time\n",
      "Weights before training: [-0.22523681991535918, -0.40860538364584814, 0.14813039726040672]\n",
      "Weights after training: [-0.2252368199153592, -0.40860538364584814, -0.2518696027395933]\n",
      "-------------\n",
      "Training 3th time\n",
      "Weights before training: [-0.2252368199153592, -0.40860538364584814, -0.2518696027395933]\n",
      "Weights after training: [-0.2252368199153592, -0.40860538364584814, -0.2518696027395933]\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "Weights weren't changed by training. Every datapoint in trainingset was classified correctly. Training is done\n"
     ]
    }
   ],
   "source": [
    "NOR.selfTrain(.1, data, norLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22523682, -0.40860538, -0.2518696 ])"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOR.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train a perceptron that returns \"True\" or \"1\" only when **at least** $m$ *of* $n$ of the features of the datapoint we feed into it are True. \n",
    "\n",
    "Let's make an at least 3 of 5 perceptron.\n",
    "\n",
    "So, for example: [1, -1, -1, 1, -1, 1] would be classified as false, since there are only two features that are true, but\n",
    "\n",
    "Think about why I have 32 different datapoints in data (clue: \"different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "threeOfFiveData = [[1, -1, -1, -1, -1, -1], [1, -1, -1, -1, -1, 1], [1, -1, -1, -1, 1, -1],\n",
    "                   [1, -1, -1, -1, 1, 1], [1, -1, -1, 1, -1, -1], [1, -1, -1, 1, -1, 1],\n",
    "                   [1, -1, -1, 1, 1, -1], [1, -1, -1, 1, 1, 1], [1, -1, 1, -1, -1, -1],\n",
    "                   [1, -1, 1, -1, -1, 1], [1, -1, 1, -1, 1, -1], [1, -1, 1, -1, 1, 1],\n",
    "                   [1, -1, 1, 1, -1, -1], [1, -1, 1, 1, -1, 1], [1, -1, 1, 1, 1, -1],\n",
    "                   [1, -1, 1, 1, 1, 1],   [1, 1, -1, -1, -1, -1], [1, 1, -1, -1, -1, 1], \n",
    "                   [1, 1, -1, -1, 1, -1],[1, 1, -1, -1, 1, 1], [1, 1, -1, 1, -1, -1], \n",
    "                   [1, 1, -1, 1, -1, 1], [1, 1, -1, 1, 1, -1], [1, 1, -1, 1, 1, 1], \n",
    "                   [1, 1, 1, -1, -1, -1], [1, 1, 1, -1, -1, 1], [1, 1, 1, -1, 1, -1], \n",
    "                   [1, 1, 1, -1, 1, 1], [1, 1, 1, 1, -1, -1], [1, 1, 1, 1, -1, 1], \n",
    "                   [1, 1, 1, 1, 1, -1], [1, 1, 1, 1, 1, 1]]\n",
    "\n",
    "\n",
    "atLeastThreeOfFiveLabels = []\n",
    "\n",
    "for d in threeOfFiveData:\n",
    "    if d.count(1)>3:\n",
    "        atLeastThreeOfFiveLabels.append(1)\n",
    "    else:\n",
    "        atLeastThreeOfFiveLabels.append(-1)\n",
    "        \n",
    "        \n",
    "threeOfFiveData = [np.array(d) for d in threeOfFiveData]\n",
    "\n",
    "\n",
    "print(len(atLeastThreeOfFiveLabels))\n",
    "print(len(threeOfFiveData))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the perceptron!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    " atLeastThreeOfFivePerceptron = arbitraryPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1th time\n",
      "Weights before training: [-0.8801881935969064, 0.47952417469596315, -2.7613859112623027, -0.020922712450633704, 0.6579093632074424, 0.9432202799425864]\n",
      "Weights after training: [-0.4801881935969065, 0.8795241746959632, -0.3613859112623025, 0.7790772875493663, 0.6579093632074424, 0.9432202799425864]\n",
      "-------------\n",
      "Training 2th time\n",
      "Weights before training: [-0.4801881935969065, 0.8795241746959632, -0.3613859112623025, 0.7790772875493663, 0.6579093632074424, 0.9432202799425864]\n",
      "Weights after training: [0.11981180640309352, 0.6795241746959633, 0.6386140887376975, 0.5790772875493664, 0.8579093632074424, 1.1432202799425863]\n",
      "-------------\n",
      "Training 3th time\n",
      "Weights before training: [0.11981180640309352, 0.6795241746959633, 0.6386140887376975, 0.5790772875493664, 0.8579093632074424, 1.1432202799425863]\n",
      "Weights after training: [-0.08018819359690649, 0.8795241746959632, 0.8386140887376976, 0.7790772875493663, 0.6579093632074424, 0.9432202799425864]\n",
      "-------------\n",
      "Training 4th time\n",
      "Weights before training: [-0.08018819359690649, 0.8795241746959632, 0.8386140887376976, 0.7790772875493663, 0.6579093632074424, 0.9432202799425864]\n",
      "Weights after training: [-0.08018819359690649, 0.8795241746959632, 0.8386140887376976, 0.7790772875493663, 0.6579093632074424, 0.9432202799425864]\n",
      "-------------\n",
      "-------------\n",
      "-------------\n",
      "Weights weren't changed by training. Every datapoint in trainingset was classified correctly. Training is done\n"
     ]
    }
   ],
   "source": [
    "atLeastThreeOfFivePerceptron.selfTrain(.1, threeOfFiveData, atLeastThreeOfFiveLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08018819,  0.87952417,  0.83861409,  0.77907729,  0.65790936,\n",
       "        0.94322028])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atLeastThreeOfFivePerceptron.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy over the training set was 100 percent, as it should be, since we trained on it!\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for datapoint in threeOfFiveData:\n",
    "    if(atLeastThreeOfFivePerceptron.predict(threeOfFiveData[i]) == atLeastThreeOfFiveLabels[i]):\n",
    "        correct = correct + 1\n",
    "    total = total + 1\n",
    "    i = i + 1\n",
    "\n",
    "print(\"Our accuracy over the training set was \" + str(int(correct*100/total)) + \" percent, as it should be, since we trained on it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our next program, we'll look at some function perceptrons CAN'T represent (XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
